# Titanic

### Análisis de Supervivientes del Titanic con Streamlit

# 2. Introducción

### Breve resumen:

El Titanic fue un transatlántico que se hundió en 1912. Su trágico destino lo ha convertido en un símbolo de desastre y, a la vez, en un rico conjunto de datos para análisis. ¿Por qué? Porque ofrece una gran cantidad de información sobre las personas a bordo (edad, sexo, clase social, etc.) y una pregunta clara: ¿quién sobrevivió y por qué? Esta combinación lo hace ideal para aplicar técnicas de aprendizaje automático y estadística.

Objetivo del proyecto: Lo que se pretende es poder analizar las causas de que hubiera tantos desaparecidos y cuales son las medidas a tomar para mejorar.

Alcance del proyecto: Lo que se va a realizar en primer lugar es un análisis de la edad, sexo y situación del camarote.
## Objetivo del proyecto:

El objetivo principal es identificar los factores que influyeron en la supervivencia de los pasajeros. Es decir, queremos responder preguntas como:

- ¿La clase social influyó en las posibilidades de sobrevivir?
- ¿El género fue un factor determinante?
- ¿La edad jugó un papel importante?
- ¿Otros factores como el número de familiares a bordo o el lugar de embarque influyeron?

### Alcance del proyecto:

Este análisis se centrará en las variables más relevantes relacionadas con los pasajeros y su supervivencia. Utilizaremos técnicas de visualización de datos y modelos de machine learning para identificar patrones y correlaciones. Las técnicas específicas que se emplearán incluyen:


- Análisis exploratorio de datos (EDA): Para comprender la distribución de las variables y detectar valores atípicos.
- Visualizaciones: Histogramas, gráficos de barras, diagramas de dispersión y heatmaps para representar los datos de forma clara y concisa.
- Modelado predictivo: Utilizaremos algoritmos de clasificación como la regresión logística para construir un modelo que prediga la probabilidad de supervivencia en función de las características de un pasajero.

### Técnicas utilizadas:

- Visualización de datos: Histogramas, diagramas de caja, gráficos de barras, etc.
- Estadística descriptiva: Medidas de tendencia central (media, mediana) y dispersión (desviación estándar).
- Aprendizaje automático: Algoritmos de clasificación supervisada.
  Evaluación de modelos: Matrices de confusión, curvas ROC, etc.

# 3. Datos Utilizados

### Fuente de los datos:

De dónde se obtuvieron los datos (Kaggle, etc.)

### Descripción general del dataset:

Número de filas, columnas, variables principales.

### Limpieza y preprocesamiento:

Como paso previo, habrá que realizar un anáisis general de la limpieza/coherencia de los datos suministrados
Breve descripción de las tareas realizadas para preparar los datos para el análisis (manejo de valores faltantes, transformación de variables, etc.).

# 4. Funcionalidades de la Aplicación

### Visualizaciones:

¿Qué tipos de visualizaciones se incluyen? (histogramas, gráficos de barras, diagramas de dispersión, etc.)

### Interactividad:

¿Cómo puede el usuario interactuar con la aplicación? (filtros, selectores, etc.)

### Análisis clave:

¿Cuáles son los hallazgos más importantes del análisis?
